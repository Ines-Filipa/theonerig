# AUTOGENERATED! DO NOT EDIT! File to edit: 12_synchro.processing.ipynb (unless otherwise specified).

__all__ = ['get_thresholds', 'get_first_high', 'reverse_detection', 'extend_timepoints', 'detect_frames', 'error_check',
           'cluster_frame_signals', 'parse_time', 'get_position_estimate', 'match_starting_position', 'display_match',
           'frame_error_correction', 'error_frame_matches', 'apply_shifts_to_reference']

# Cell
import numpy as np
import datetime
import glob
import os

# Cell
def get_thresholds(data):
    max_val = max(data[len(data)//2:len(data)//2 + 10000000]) #Looking for a max in a portion of the data, from the middle
    high_thresh = max_val*3/4 # High threshold set at 3/4th of the max
    low_thresh  = max_val*1/4
    return low_thresh, high_thresh

# Cell
def get_first_high(data, threshold):
    if np.any(data>threshold):
        return np.argmax(data>threshold)
    else:
        return -1

def reverse_detection(data, frame_timepoints, low_threshold, increment):
    new_timepoints = []
    new_signals = []

    safe_increment = int(increment * 105/100)

    i = frame_timepoints[0]-safe_increment
    while i>0:
        data_slice = data[i:i+increment//2]
        if np.any(data_slice > low_threshold):
            i = i+np.argmax(data_slice > low_threshold)
        else:
            break #No low threshold crossing found -> no more frames to detect
        new_timepoints.append(i)
        i-= safe_increment #We move backward of almost a frame

    return new_timepoints[::-1]

def extend_timepoints(frame_timepoints, n=10):
    frame_timepoints = np.array(frame_timepoints)
    typical_distance = int(np.mean(np.diff(frame_timepoints)))
    extended_tp = [frame_timepoints[0]-(i+1)*typical_distance for i in range(n) if (frame_timepoints[0]-(i+1)*typical_distance)>0]
    return extended_tp[::-1]

def detect_frames(data, low_threshold, high_threshold, increment):
    frame_timepoints, frame_signals = [], []
    safe_increment = int(increment*95/100)

    first_high = get_first_high(data, high_threshold)
    if first_high == -1:
        print("No high frame detected. Detection can't work.")
        return

    frame_timepoints.append(first_high)
    frame_signals.append(1)

    new_timepoints   = reverse_detection(data, frame_timepoints, low_threshold, increment)
    new_extrapolated = extend_timepoints(new_timepoints)
    frame_timepoints = new_extrapolated + new_timepoints + frame_timepoints
    frame_signals    = [0]*(len(new_timepoints)+len(new_extrapolated)) + frame_signals

    i = first_high + safe_increment
    while i < len(data):
        data_slice = data[i:i+increment//2]
        if np.any(data_slice>low_threshold):
            i = i+np.argmax(data_slice>low_threshold)
        else:
            break #This frame sequence is over. Pass the next sequence through this function if there are frames left
        frame_timepoints.append(i)
        frame_signals.append(int(np.any(data_slice > high_threshold)))
        i += safe_increment

    frame_timepoints = np.array(frame_timepoints)
    frame_signals    = np.array(frame_signals)
    frame_timepoints = frame_timepoints - 3 # A slight shift of the timepoints
                                            # to include the begginning of the peaks.

    error_check(frame_timepoints)

#     self.frame_start_time = self.record_start_time + datetime.timedelta(0,int(self.frame_timepoints[0]/self.sampling_rate))
#     self.frame_end_time = self.record_start_time + datetime.timedelta(0,int(self.frame_timepoints[-1]/self.sampling_rate))

    return frame_timepoints, frame_signals

def error_check(frame_tp):
    deriv_frame_tp = np.diff(frame_tp)
    error_len_th = np.mean(deriv_frame_tp)+np.std(deriv_frame_tp)*6

    error_frames = np.abs(deriv_frame_tp)>error_len_th
    if np.any(error_frames):
        print("Error in timepoints detected in frames", np.where(error_frames)[0],
              "at timepoint", frame_tp[np.where(error_frames)[0]])

# Cell
def cluster_frame_signals(data, frame_timepoints, n_cluster=5):
    frame_aucs = np.fromiter(map(np.trapz, np.split(data, frame_timepoints)), float)
    if frame_timepoints[0] != 0: #We need to remove the first part if it wasn't a full frame
        frame_aucs = frame_aucs[1:]
    frame_auc_sorted = np.sort(frame_aucs)
    deriv = np.array(frame_auc_sorted[1:]-frame_auc_sorted[:-1])
    deriv[:5]  = 0 #removing tails values that can show weird stuff
    deriv[-5:] = 0
    threshold_peak = np.std(deriv)*3
    n          = n_cluster - 1
    idx_gaps = np.zeros(n+3, dtype="int")
    tmp_deriv = deriv.copy()
    for i in range(n+3): #Detecting more peaks than needed and then taking them starting on the right
        if tmp_deriv[np.argmax(tmp_deriv)] < threshold_peak:
            if i<n_cluster-1:
                print("Less transition in AUC detected than needed, results will be weird")
            break
        idx_gaps[i] = np.argmax(tmp_deriv)
        tmp_deriv[idx_gaps[i]] = 0
    idx_gaps = np.sort(idx_gaps)
    idx_gaps = idx_gaps[-4:]
    thresholds = np.zeros(n, dtype="float")
    for i, idx in enumerate(idx_gaps):
        thresholds[i] = (frame_auc_sorted[idx+1] + frame_auc_sorted[idx])/2

    return np.array([np.sum(auc>thresholds) for auc in frame_aucs], dtype=int)

# Cell
def parse_time(time_str, pattern="%y%m%d_%H%M%S"):
    return datetime.datetime.strptime(time_str, pattern)

def get_position_estimate(stim_time, record_time, sampling_rate):
    if stim_time < record_time:
        return -1
    else:
        return (stim_time - record_time).seconds * sampling_rate

# Cell
def match_starting_position(frame_timepoints, frame_signals, stim_signals, estimate_start):
    stim_matching_len = min(600, np.where(np.diff(stim_signals)!=0)[0][50]) #Way of getting the 50th change in the signals
    #But not higher than 600 (correspond to 10s, and is necessary for moving gratings)
#     stim_matching_len = 50
    idx_estimate = np.argmax(frame_timepoints>estimate_start)
    search_slice = slice(max(0, idx_estimate-1000), min(idx_estimate+1000, len(frame_signals)))
#     diff_signals = np.diff(frame_signals[search_slice])
#     diff_stim    = np.diff(stim_signals[:stim_matching_len])
#     return search_slice.start + np.argmax(np.correlate(diff_signals, diff_stim))
    return search_slice.start + np.argmax(np.correlate(frame_signals[search_slice],
                                                       stim_signals[:stim_matching_len]))

def display_match(match_position, recorded=None, reference=None, corrected=None, len_line=50):
    start, mid, end = 0, len(reference)//2, len(reference)-len_line
    for line in [start, mid, end]:
        if reference is not None:
            print("REF ["+str(line)+"] "," ".join(map(str,map(int, reference[line:line+len_line]))))
        if recorded is not None:
            print("REC ["+str(line)+"] "," ".join(map(str,map(int, recorded[line+match_position:line+len_line+match_position]))))
        if corrected is not None:
            print("COR ["+str(line)+"] "," ".join(map(str,map(int, corrected[line:line+len_line]))))
        print()

# Cell
def frame_error_correction(signals, unpacked):
    intensity, marker, shader, op_log = apply_shifts_to_reference(signals, unpacked, range_=5)
    error_frames, replacements = error_frame_matches(signals, marker, range_=5)
    intensity[error_frames]    = intensity[replacements]
    marker[error_frames]       = marker[replacements]
    if shader is not None:
        shader[error_frames] = shader[replacements]
    return (intensity, marker, shader), op_log

def error_frame_matches(signals, marker, range_):
    error_frames = np.nonzero(signals!=marker)[0]
    where_equal = [((np.where(marker[err_id-range_:err_id+(range_+1)] == signals[err_id])[0]) - range_) for err_id in error_frames]

    #filtering out the frames where no match was found
    tmp    = np.array([[wheq,err] for (wheq, err) in zip(where_equal, error_frames) if len(wheq)>0])
    where_equal  = tmp[:,0]
    error_frames = tmp[:,1]

    #Choosing among the equal frame signals the one that is the closest
    closest_equal = [wheq[(np.abs(wheq)).argmin()] for wheq in where_equal]

    error_frames = np.array(error_frames, dtype=int)
    replacements  = error_frames + np.array(closest_equal, dtype=int)

    return error_frames, replacements

def apply_shifts_to_reference(signals, unpacked, range_):
    intensity, marker, shader = unpacked[0], unpacked[1], None
    if len(unpacked)==3:
        shader = unpacked[2]

    shift_detected = True
    operation_log = []
    while shift_detected:
        error_frames, replacements = error_frame_matches(signals, marker, range_)

        all_shifts = np.zeros(len(marker))
        all_shifts[error_frames] = replacements-error_frames
        all_shifts_conv = np.convolve(all_shifts, [.05]*20, mode="same") #Averaging the shifts to find consistant shifts

        shift_detected = np.any(np.abs(all_shifts_conv)>.5)
        if shift_detected: #iF the -.5 threshold is crossed, we insert a "fake" frame in the reference and we repeat the operation

            change_idx = np.argmax(np.abs(all_shifts_conv)>.5)
            if all_shifts_conv[change_idx]>.5:#Need to delete frame in reference
                operation_log.append([int(change_idx), "del"])
                marker = np.concatenate((marker[:change_idx], marker[change_idx+1:], [0]))
                intensity = np.concatenate((intensity[:change_idx], intensity[change_idx+1:], np.zeros((1,*intensity.shape[1:]))))
                if shader is not None:
                    shader = np.concatenate((shader[:change_idx], shader[change_idx+1:], np.zeros((1,*shader.shape[1:]))))

            else:#Need to insert frame in reference
                operation_log.append([int(change_idx), "ins"])
                #inserting a frame and excluding the last frame to keep the references the same length
                marker     = np.insert(marker, change_idx, marker[change_idx], axis=0)[:-1]
                intensity  = np.insert(intensity, change_idx, intensity[change_idx], axis=0)[:-1]
                if shader is not None:
                    shader = np.insert(shader, change_idx, shader[change_idx], axis=0)[:-1]
    return intensity, marker, shader, operation_log