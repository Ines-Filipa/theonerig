#AUTOGENERATED! DO NOT EDIT! File to edit: dev/01_utils.ipynb (unless otherwise specified).

__all__ = ['extend_sync_timepoints', 'align_sync_timepoints', 'downsample_to_timepoints']

#Cell
import numpy as np
from typing import Dict, Tuple, Sequence, Union, Callable
import scipy.interpolate as interpolate

#Cell
def extend_sync_timepoints(timepoints:np.ndarray, signals:np.ndarray,
                           up_bound, low_bound=0) -> Tuple[DataChunk, DataChunk]:
    """From `timepoints` and `signals` list, extend it on the left so it includes `low_bound`, and extend it
    up to `up_bound`.
    Return the new timepoints and signals as DataChunk objets with the number of timepoints added to the left
    as a tuple.
    """
    assert len(timepoints) == len(signals)
    timepoints = np.array(timepoints)
    signals = np.array(signals)
    spb = np.mean(timepoints[1:]-timepoints[:-1]) #spf: sample_per_bin

    #Left and right side are just prolongation of the sample_times up
    # from (0-sample_per_fr) to (len+sample_per_fr) so it covers all timepoints
    left_side  = np.arange(timepoints[0]-spb , low_bound - spb, -spb)[::-1].astype(int)
    right_side = np.arange(timepoints[-1]+spb,  up_bound + spb,  spb).astype(int)

    new_timepoints = np.concatenate((left_side,
                                     timepoints,
                                     right_side))

    timepoint_chunk = DataChunk(data=new_timepoints, idx=0, group="sync")
    signal_chunk    = DataChunk(data=signals, idx=len(left_side), group="sync")
    return (timepoint_chunk, signal_chunk, len(left_side))

#Cell
def align_sync_timepoints(timepoints:np.ndarray, signals:np.ndarray,
                          ref_timepoints:DataChunk, ref_signals:DataChunk,
                          shift=None) -> DataChunk:
    """Align the `signals` of a `timepoints` timeserie to a reference `ref_timepoints` with the corresponding
    `ref_signals`. A `shift` can be directly specified, otherwise it will be searched by finding the maximum
    of the correlations of the two signals timeseries.
    Returns a DataChunk of the aligned timepoints"""
    assert len(timepoints) == len(signals)
    timepoints = np.array(timepoints)
    signals = np.array(signals)

    if shift is None: #If a shift is provided we use it, otherwise we use the max correlation
        shift = np.argmax(np.correlate(ref_signals, signals, mode="valid"))

    spb = np.mean(timepoints[1:]-timepoints[:-1]) #spf: sample_per_bin
    n_left  = ref_signals.idx + shift
    n_right = (len(ref_timepoints)
               - len(timepoints)
               - n_left)

    init_left  = timepoints[0]-spb
    init_right = timepoints[-1]+spb

    left_side  = np.arange(init_left , init_left-(spb*n_left+1), -spb)[:n_left][::-1].astype(int)
    right_side = np.arange(init_right, init_right+(spb*n_right+1), spb)[:n_right].astype(int)

    new_timepoints = np.concatenate((left_side,
                                     timepoints,
                                     right_side))
    return DataChunk(data=new_timepoints, idx=0, group="sync")

#Cell
def downsample_to_timepoints(timepoints:np.ndarray, data:np.ndarray,
                             ref_timepoints:DataChunk, group="data") -> DataChunk:
    """Downsample the `data` at the `timepoints` to a smaller array at the timepoints of `ref_timepoints`.
    Return a DataChunck of the downsampled data belonging to `group`."""

    assert len(timepoints) == len(data)
    timepoints = np.array(timepoints)
    data = np.array(data)

    start_idx = np.argmax(timepoints[0] <=ref_timepoints)
    stop_idx  = np.argmax(timepoints[-1]<=ref_timepoints)

    distance = (np.argmax(timepoints>ref_timepoints[start_idx+1])
            - np.argmax(timepoints>ref_timepoints[start_idx]))

    #Use numpy convolution to smooth. Could be generalized to higher dimension data
    # with scipy.ndimage.convolve1d
    smooth_data = np.convolve(data, [1/distance]*distance, mode="same")
    new_data = np.interp(ref_timepoints[start_idx:stop_idx], timepoints, smooth_data)

    idx = ref_timepoints.idx + start_idx
    return DataChunk(data=new_data, idx = idx, group=group)