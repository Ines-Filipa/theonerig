{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp synchro.extracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os, glob\n",
    "import csv\n",
    "import re\n",
    "\n",
    "from theonerig.synchro.io import *\n",
    "from theonerig.utils import *\n",
    "\n",
    "def get_QDSpy_logs(log_dir):\n",
    "    log_names = glob.glob(os.path.join(log_dir,'[0-9]*.log'))\n",
    "#     log_names = [os.path.basename(log_name) for log_name in log_names]\n",
    "    qdspy_logs = [QDSpy_log(log_name) for log_name in log_names]\n",
    "    for qdspy_log in qdspy_logs:\n",
    "        qdspy_log.find_stimuli()\n",
    "    return qdspy_logs\n",
    "\n",
    "class QDSpy_log:\n",
    "    def __init__(self, log_path):\n",
    "        self.log_path = log_path\n",
    "        self.stimuli = []\n",
    "        self.comments = []\n",
    "        \n",
    "    def _extract_data(self, data_line):\n",
    "        data = data_line[data_line.find('{')+1:data_line.find('}')]\n",
    "        data_splitted = data.split(',')\n",
    "        data_dict = {}\n",
    "        for data in data_splitted:\n",
    "            ind = data.find(\"'\")\n",
    "            if type(data[data.find(\":\")+2:]) is str:\n",
    "                data_dict[data[ind+1:data.find(\"'\",ind+1)]] = data[data.find(\":\")+2:][1:-1]\n",
    "            else:\n",
    "                data_dict[data[ind+1:data.find(\"'\",ind+1)]] = data[data.find(\":\")+2:]\n",
    "        return data_dict\n",
    "\n",
    "    def _extract_time(self,data_line):\n",
    "        line = '%s' % data_line\n",
    "        year = int(line[0:4])\n",
    "        month = int(line[4:6])\n",
    "        day = int(line[6:8])\n",
    "        hour =int(line[9:11])\n",
    "        minute = int(line[11:13])\n",
    "        second = int(line[13:15])\n",
    "        result = datetime.datetime(year,month,day,hour,minute,second)\n",
    "        return result\n",
    "    \n",
    "    def _extract_delay(self,data_line):\n",
    "        ind = data_line.find('#')\n",
    "        index_frame = int(data_line[ind+1:data_line.find(' ',ind)])\n",
    "        ind = data_line.find('was')\n",
    "        delay = float(data_line[ind:].split(\" \")[1])\n",
    "        return (index_frame, delay)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"\\n\".join([str(stim) for stim in self.stimuli])\n",
    "    \n",
    "    @property\n",
    "    def n_stim(self):\n",
    "        return len(self.stimuli)\n",
    "\n",
    "    @property\n",
    "    def stim_names(self):\n",
    "        return [stim.name for stim in self.stimuli]\n",
    "    \n",
    "    def find_stimuli(self):\n",
    "        \"\"\"Find the stimuli in the log file and return the list of the stimuli\n",
    "        found by this object.\"\"\"\n",
    "        with open(self.log_path, 'r', encoding=\"ISO-8859-1\") as log_file:\n",
    "            for line in log_file:\n",
    "                if \"DATA\" in line:\n",
    "                    data_juice = self._extract_data(line)\n",
    "                    if 'stimState' in data_juice.keys():\n",
    "                        if data_juice['stimState'] == \"STARTED\" :\n",
    "                            curr_stim = Stimulus(self._extract_time(line))\n",
    "                            curr_stim.set_parameters(data_juice)\n",
    "                            self.stimuli.append(curr_stim)\n",
    "                            stimulus_ON = True\n",
    "                        elif data_juice['stimState'] == \"FINISHED\" or data_juice['stimState'] == \"ABORTED\":\n",
    "                            curr_stim.is_aborted = data_juice['stimState'] == \"ABORTED\"\n",
    "                            curr_stim.stop_time = self._extract_time(line)\n",
    "                            stimulus_ON = False\n",
    "\n",
    "                    elif 'userComment' in data_juice.keys():\n",
    "                        pass\n",
    "                        #print(\"userComment, use it to bind logs to records\")\n",
    "                    elif stimulus_ON: #Information on stimulus parameters\n",
    "                        curr_stim.set_parameters(data_juice)\n",
    "    #                elif 'probeX' in data_juice.keys():\n",
    "            #            print(\"Probe center not implemented yet\")\n",
    "                if \"WARNING\" in line and \"dt of frame\" and stimulus_ON:\n",
    "                    curr_stim.frame_delay.append(self._extract_delay(line))\n",
    "        return self.stimuli\n",
    "    \n",
    "class Stimulus:\n",
    "    \"\"\"Stimulus object containing information about it's presentation.\n",
    "    \"\"\"\n",
    "    def __init__(self,start):\n",
    "        self.start_time = start\n",
    "        self.stop_time = None\n",
    "        self.parameters = {}\n",
    "        self.frame_delay = []\n",
    "        self.name = \"NoName\"\n",
    "\n",
    "        self.is_recorded = False\n",
    "        self.non_matching = False\n",
    "        self.is_aborted = False\n",
    "\n",
    "        self.md5 = None\n",
    "        #self.compiled_id = None  # ! This is not a reliable value after storage if DB change\n",
    "        self.barcode = None\n",
    "\n",
    "        self.first_frame_idx = None\n",
    "\n",
    "        self.intensity = None\n",
    "        self.marker    = None\n",
    "        self.shader    = None\n",
    "        self.theor_intensity = None\n",
    "        self.theor_marker    = None\n",
    "        self.theor_shader    = None\n",
    "        \n",
    "        self.frame_error_idx = [] #The errors detected by comparing the signals\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        self.parameters.update(parameters)\n",
    "        if \"_sName\" in parameters.keys():\n",
    "            self.name = parameters[\"_sName\"]\n",
    "        if \"stimMD5\" in parameters.keys():\n",
    "            self.md5 = parameters[\"stimMD5\"]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"%s %s at %s\" %(self.name+\" \"*(24-len(self.name)),self.md5,self.start_time)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def unpack_stim_npy(npy_dir, md5_hash):\n",
    "    inten  = np.load(glob.glob(os.path.join(npy_dir, \"*_intensities_\"+md5_hash+\".npy\"))[0])\n",
    "    marker = np.load(glob.glob(os.path.join(npy_dir, \"*_marker_\"+md5_hash+\".npy\"))[0])\n",
    "    \n",
    "    tmp = glob.glob(os.path.join(npy_dir, \"*_shader_\"+md5_hash+\".npy\"))\n",
    "    shader, unpack_shader = None, None\n",
    "    if len(tmp)!=0:\n",
    "        shader        = np.load(tmp[0])\n",
    "        unpack_shader = np.empty((np.sum(marker[:,0]), *shader.shape[1:]))\n",
    "\n",
    "    unpack_inten  = np.empty((np.sum(marker[:,0]), *inten.shape[1:]))\n",
    "    unpack_marker = np.empty(np.sum(marker[:,0]))\n",
    "\n",
    "    cursor = 0\n",
    "    for i, n_frame in enumerate(marker[:,0]):\n",
    "        unpack_inten[cursor:cursor+n_frame] = inten[i]\n",
    "        unpack_marker[cursor:cursor+n_frame] = marker[i, 1]\n",
    "        if shader is not None:\n",
    "            unpack_shader[cursor:cursor+n_frame] = shader[i]\n",
    "        cursor += n_frame\n",
    "    \n",
    "    return unpack_inten, unpack_marker, unpack_shader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def extract_spyking_circus_results(dir_, record_basename):\n",
    "    phy_dir  = os.path.join(dir_,record_basename+\"/\"+record_basename+\".GUI\")\n",
    "    phy_dict = phy_results_dict(phy_dir)\n",
    "    \n",
    "    good_clusters = []\n",
    "    with open(os.path.join(phy_dir,'cluster_group.tsv'), 'r') as tsvfile:\n",
    "        spamreader = csv.reader(tsvfile, delimiter='\\t', quotechar='|')\n",
    "        for i,row in enumerate(spamreader):\n",
    "            if row[1] == \"good\":\n",
    "                good_clusters.append(int(row[0]))\n",
    "    good_clusters = np.array(good_clusters)\n",
    "    \n",
    "    phy_dict[\"good_clusters\"] = good_clusters\n",
    "    \n",
    "    return phy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def extract_best_pupil(fn):\n",
    "    pupil = np.load(fn)\n",
    "    filtered_pupil = np.empty((len(pupil), 6))\n",
    "    for i, detected in enumerate(pupil):\n",
    "        if len(detected)>0:\n",
    "            best = detected[0]\n",
    "            for detect in detected[1:]:\n",
    "                if detect[5]>best[5]:\n",
    "                    best = detect\n",
    "            filtered_pupil[i] = np.array(best)\n",
    "        else:\n",
    "            filtered_pupil[i] = np.array([0,0,0,0,0,0])\n",
    "    return filtered_pupil\n",
    "\n",
    "def stack_len_extraction(stack_info_dir):\n",
    "    ptrn_nFrame = r\".*number=(\\d*) .*\"\n",
    "    l_epochs = []\n",
    "    for fn in glob.glob(os.path.join(stack_info_dir, \"*.txt\")):\n",
    "        with open(fn) as f:\n",
    "            line = f.readline()\n",
    "            l_epochs.append(int(re.findall(ptrn_nFrame, line)[0]))\n",
    "    return l_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_utils.ipynb.\n",
      "Converted 02_processing.ipynb.\n",
      "Converted 03_modelling.ipynb.\n",
      "Converted 04_plotting.ipynb.\n",
      "Converted 05_database.ipynb.\n",
      "Converted 10_synchro.io.ipynb.\n",
      "Converted 11_synchro.extracting.ipynb.\n",
      "Converted 12_synchro.processing.ipynb.\n",
      "Converted 99_testdata.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
