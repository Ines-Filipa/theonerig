{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp synchro.processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import datetime\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_thresholds(data):\n",
    "    max_val = max(data[len(data)//2:len(data)//2 + 10000000]) #Looking for a max in a portion of the data, from the middle\n",
    "    high_thresh = max_val*3/4 # High threshold set at 3/4th of the max\n",
    "    low_thresh  = max_val*1/4\n",
    "    return low_thresh, high_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_first_high(data, threshold):\n",
    "    if np.any(data>threshold):\n",
    "        return np.argmax(data>threshold)\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def reverse_detection(data, frame_timepoints, low_threshold, increment):\n",
    "    new_timepoints = []\n",
    "    new_signals = []\n",
    "\n",
    "    safe_increment = int(increment * 105/100)\n",
    "\n",
    "    i = frame_timepoints[0]-safe_increment\n",
    "    while i>0:\n",
    "        data_slice = data[i:i+increment//2]\n",
    "        if np.any(data_slice > low_threshold):\n",
    "            i = i+np.argmax(data_slice > low_threshold)\n",
    "        else:\n",
    "            break #No low threshold crossing found -> no more frames to detect\n",
    "        new_timepoints.append(i)\n",
    "        i-= safe_increment #We move backward of almost a frame\n",
    "\n",
    "    return new_timepoints[::-1]\n",
    "    \n",
    "def extend_timepoints(frame_timepoints, n=10):\n",
    "    frame_timepoints = np.array(frame_timepoints)\n",
    "    typical_distance = int(np.mean(np.diff(frame_timepoints)))\n",
    "    extended_tp = [frame_timepoints[0]-(i+1)*typical_distance for i in range(n) if (frame_timepoints[0]-(i+1)*typical_distance)>0]\n",
    "    return extended_tp[::-1]\n",
    "    \n",
    "def detect_frames(data, low_threshold, high_threshold, increment):\n",
    "    frame_timepoints, frame_signals = [], []\n",
    "    safe_increment = int(increment*95/100)\n",
    "\n",
    "    first_high = get_first_high(data, high_threshold)\n",
    "    if first_high == -1:\n",
    "        print(\"No high frame detected. Detection can't work.\")\n",
    "        return\n",
    "\n",
    "    frame_timepoints.append(first_high)\n",
    "    frame_signals.append(1)\n",
    "\n",
    "    new_timepoints   = reverse_detection(data, frame_timepoints, low_threshold, increment)\n",
    "    new_extrapolated = extend_timepoints(new_timepoints)\n",
    "    frame_timepoints = new_extrapolated + new_timepoints + frame_timepoints\n",
    "    frame_signals    = [0]*(len(new_timepoints)+len(new_extrapolated)) + frame_signals\n",
    "\n",
    "    i = first_high + safe_increment\n",
    "    while i < len(data):\n",
    "        data_slice = data[i:i+increment//2]\n",
    "        if np.any(data_slice>low_threshold):\n",
    "            i = i+np.argmax(data_slice>low_threshold)\n",
    "        else:\n",
    "            break #This frame sequence is over. Pass the next sequence through this function if there are frames left\n",
    "        frame_timepoints.append(i)\n",
    "        frame_signals.append(int(np.any(data_slice > high_threshold)))\n",
    "        i += safe_increment\n",
    "\n",
    "    frame_timepoints = np.array(frame_timepoints)\n",
    "    frame_signals    = np.array(frame_signals)\n",
    "    frame_timepoints = frame_timepoints - 3 # A slight shift of the timepoints \n",
    "                                            # to include the begginning of the peaks.\n",
    "        \n",
    "    error_check(frame_timepoints)\n",
    "\n",
    "#     self.frame_start_time = self.record_start_time + datetime.timedelta(0,int(self.frame_timepoints[0]/self.sampling_rate))\n",
    "#     self.frame_end_time = self.record_start_time + datetime.timedelta(0,int(self.frame_timepoints[-1]/self.sampling_rate))\n",
    "\n",
    "    return frame_timepoints, frame_signals\n",
    "\n",
    "def error_check(frame_tp):\n",
    "    deriv_frame_tp = np.diff(frame_tp)\n",
    "    error_len_th = np.mean(deriv_frame_tp)+np.std(deriv_frame_tp)*6\n",
    "\n",
    "    error_frames = np.abs(deriv_frame_tp)>error_len_th\n",
    "    if np.any(error_frames):\n",
    "        print(\"Error in timepoints detected in frames\", np.where(error_frames)[0], \n",
    "              \"at timepoint\", frame_tp[np.where(error_frames)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def cluster_frame_signals(data, frame_timepoints, n_cluster=5):\n",
    "    frame_aucs = np.fromiter(map(np.trapz, np.split(data, frame_timepoints)), float)\n",
    "    if frame_timepoints[0] != 0: #We need to remove the first part if it wasn't a full frame\n",
    "        frame_aucs = frame_aucs[1:]\n",
    "    frame_auc_sorted = np.sort(frame_aucs)\n",
    "    deriv = np.array(frame_auc_sorted[1:]-frame_auc_sorted[:-1])\n",
    "    deriv[:5]  = 0 #removing tails values that can show weird stuff\n",
    "    deriv[-5:] = 0\n",
    "    threshold_peak = np.std(deriv)*3\n",
    "    n          = n_cluster - 1\n",
    "    idx_gaps = np.zeros(n+3, dtype=\"int\")\n",
    "    tmp_deriv = deriv.copy()\n",
    "    for i in range(n+3): #Detecting more peaks than needed and then taking them starting on the right\n",
    "        if tmp_deriv[np.argmax(tmp_deriv)] < threshold_peak:\n",
    "            if i<n_cluster-1:\n",
    "                print(\"Less transition in AUC detected than needed, results will be weird\")\n",
    "            break\n",
    "        idx_gaps[i] = np.argmax(tmp_deriv)\n",
    "        tmp_deriv[idx_gaps[i]] = 0\n",
    "    idx_gaps = np.sort(idx_gaps)\n",
    "    idx_gaps = idx_gaps[-4:]\n",
    "    thresholds = np.zeros(n, dtype=\"float\")\n",
    "    for i, idx in enumerate(idx_gaps):\n",
    "        thresholds[i] = (frame_auc_sorted[idx+1] + frame_auc_sorted[idx])/2\n",
    "\n",
    "    return np.array([np.sum(auc>thresholds) for auc in frame_aucs], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def parse_time(time_str, pattern=\"%y%m%d_%H%M%S\"):\n",
    "    return datetime.datetime.strptime(time_str, pattern)\n",
    "\n",
    "def get_position_estimate(stim_time, record_time, sampling_rate):\n",
    "    if stim_time < record_time:\n",
    "        return -1\n",
    "    else:\n",
    "        return (stim_time - record_time).seconds * sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def match_starting_position(frame_timepoints, frame_signals, stim_signals, estimate_start):\n",
    "    stim_matching_len = min(600, np.where(np.diff(stim_signals)!=0)[0][50]) #Way of getting the 50th change in the signals\n",
    "    #But not higher than 600 (correspond to 10s, and is necessary for moving gratings)\n",
    "#     stim_matching_len = 50\n",
    "    idx_estimate = np.argmax(frame_timepoints>estimate_start)\n",
    "    search_slice = slice(max(0, idx_estimate-1000), min(idx_estimate+1000, len(frame_signals)))\n",
    "#     diff_signals = np.diff(frame_signals[search_slice])\n",
    "#     diff_stim    = np.diff(stim_signals[:stim_matching_len])\n",
    "#     return search_slice.start + np.argmax(np.correlate(diff_signals, diff_stim))\n",
    "    return search_slice.start + np.argmax(np.correlate(frame_signals[search_slice], \n",
    "                                                       stim_signals[:stim_matching_len]))\n",
    "\n",
    "def display_match(match_position, recorded=None, reference=None, corrected=None, len_line=50):\n",
    "    start, mid, end = 0, len(reference)//2, len(reference)-len_line\n",
    "    for line in [start, mid, end]:\n",
    "        if reference is not None:\n",
    "            print(\"REF [\"+str(line)+\"] \",\" \".join(map(str,map(int, reference[line:line+len_line]))))\n",
    "        if recorded is not None:\n",
    "            print(\"REC [\"+str(line)+\"] \",\" \".join(map(str,map(int, recorded[line+match_position:line+len_line+match_position]))))\n",
    "        if corrected is not None:\n",
    "            print(\"COR [\"+str(line)+\"] \",\" \".join(map(str,map(int, corrected[line:line+len_line]))))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def frame_error_correction(signals, unpacked):\n",
    "    intensity, marker, shader, op_log = apply_shifts_to_reference(signals, unpacked, range_=5)\n",
    "    error_frames, replacements = error_frame_matches(signals, marker, range_=5)\n",
    "    intensity[error_frames]    = intensity[replacements]\n",
    "    marker[error_frames]       = marker[replacements]\n",
    "    if shader is not None:\n",
    "        shader[error_frames] = shader[replacements]\n",
    "    return (intensity, marker, shader), op_log\n",
    "\n",
    "def error_frame_matches(signals, marker, range_):\n",
    "    error_frames = np.nonzero(signals!=marker)[0]\n",
    "    where_equal = [((np.where(marker[err_id-range_:err_id+(range_+1)] == signals[err_id])[0]) - range_) for err_id in error_frames]\n",
    "    \n",
    "    #filtering out the frames where no match was found\n",
    "    tmp    = np.array([[wheq,err] for (wheq, err) in zip(where_equal, error_frames) if len(wheq)>0])\n",
    "    where_equal  = tmp[:,0]\n",
    "    error_frames = tmp[:,1]\n",
    "\n",
    "    #Choosing among the equal frame signals the one that is the closest\n",
    "    closest_equal = [wheq[(np.abs(wheq)).argmin()] for wheq in where_equal]\n",
    "    \n",
    "    error_frames = np.array(error_frames, dtype=int)\n",
    "    replacements  = error_frames + np.array(closest_equal, dtype=int)\n",
    "\n",
    "    return error_frames, replacements\n",
    "\n",
    "def apply_shifts_to_reference(signals, unpacked, range_):\n",
    "    intensity, marker, shader = unpacked[0], unpacked[1], None\n",
    "    if len(unpacked)==3:\n",
    "        shader = unpacked[2]\n",
    "\n",
    "    shift_detected = True\n",
    "    operation_log = []\n",
    "    while shift_detected:\n",
    "        error_frames, replacements = error_frame_matches(signals, marker, range_)\n",
    "\n",
    "        all_shifts = np.zeros(len(marker))\n",
    "        all_shifts[error_frames] = replacements-error_frames\n",
    "        all_shifts_conv = np.convolve(all_shifts, [.05]*20, mode=\"same\") #Averaging the shifts to find consistant shifts\n",
    "\n",
    "        shift_detected = np.any(np.abs(all_shifts_conv)>.5)\n",
    "        if shift_detected: #iF the -.5 threshold is crossed, we insert a \"fake\" frame in the reference and we repeat the operation\n",
    "\n",
    "            change_idx = np.argmax(np.abs(all_shifts_conv)>.5)\n",
    "            if all_shifts_conv[change_idx]>.5:#Need to delete frame in reference\n",
    "                operation_log.append([int(change_idx), \"del\"])\n",
    "                marker = np.concatenate((marker[:change_idx], marker[change_idx+1:], [0]))\n",
    "                intensity = np.concatenate((intensity[:change_idx], intensity[change_idx+1:], np.zeros((1,*intensity.shape[1:]))))\n",
    "                if shader is not None:\n",
    "                    shader = np.concatenate((shader[:change_idx], shader[change_idx+1:], np.zeros((1,*shader.shape[1:]))))\n",
    "\n",
    "            else:#Need to insert frame in reference\n",
    "                operation_log.append([int(change_idx), \"ins\"])\n",
    "                #inserting a frame and excluding the last frame to keep the references the same length\n",
    "                marker     = np.insert(marker, change_idx, marker[change_idx], axis=0)[:-1] \n",
    "                intensity  = np.insert(intensity, change_idx, intensity[change_idx], axis=0)[:-1]\n",
    "                if shader is not None:\n",
    "                    shader = np.insert(shader, change_idx, shader[change_idx], axis=0)[:-1]\n",
    "    return intensity, marker, shader, operation_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_utils.ipynb.\n",
      "Converted 02_processing.ipynb.\n",
      "Converted 03_modelling.ipynb.\n",
      "Converted 04_plotting.ipynb.\n",
      "Converted 05_database.ipynb.\n",
      "Converted 10_synchro.io.ipynb.\n",
      "Converted 11_synchro.extracting.ipynb.\n",
      "Converted 12_synchro.processing.ipynb.\n",
      "Converted 99_testdata.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
